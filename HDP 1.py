# -*- coding: utf-8 -*-
"""HDP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XtHzLIB1lmlsFL4bK-8zt00prOol1qdn
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import pickle
from google.colab import files

# loading the csv data to a Pandas DataFrame
heart_data = pd.read_csv('heart_disease_data.csv')

heart_data.to_pickle('heart_disease_data.pkl')

files.download('heart_disease_data.pkl')

# print first 5 rows of the dataset
heart_data.head()

# print last 5 rows of the dataset
heart_data.tail()

# number of rows and columns in the dataset
heart_data.shape

#checking correlation between features
plt.figure(figsize=(11, 6))
sns.heatmap(heart_data.corr(), annot=True, linewidths=2, cmap ='RdYlGn')
plt.show()

# getting some info about the data
heart_data.info()

# checking for missing values
heart_data.isnull().sum()

#Visualizing Null values
plt.figure(figsize=(9,5))
ax = sns.barplot(x=heart_data.isna().sum(),
           y=heart_data.columns, orient='h')
for p in ax.patches:
    ax.annotate(text=f"{p.get_width():.0f}", 
                xy=(p.get_width(), p.get_y()+p.get_height()/2),
                xytext=(5, 0), textcoords='offset points', 
                ha="left", va="center",
               )
plt.grid(False)
plt.show()

# statistical measures about the data
heart_data.describe()

# checking the distribution of Target Variable
heart_data['target'].value_counts()

X = heart_data.drop(columns='target', axis=1)
Y = heart_data['target']

print(X)

print(Y)

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=2)

print(X.shape, X_train.shape, X_test.shape)

# create logistic regression model
lr_model = LogisticRegression()

# train the logistic regression model
lr_model.fit(X_train, Y_train)

# accuracy on training data
lr_X_train_prediction = lr_model.predict(X_train)
lr_training_data_accuracy = accuracy_score(lr_X_train_prediction, Y_train)
print('Logistic Regression Accuracy on Training data : ', lr_training_data_accuracy)

# accuracy on test data
lr_X_test_prediction = lr_model.predict(X_test)
lr_test_data_accuracy = accuracy_score(lr_X_test_prediction, Y_test)
print('Logistic Regression Accuracy on Test data : ', lr_test_data_accuracy)

# calculate accuracy on training and test data
lr_X_train_prediction = lr_model.predict(X_train)
lr_training_data_accuracy = accuracy_score(lr_X_train_prediction, Y_train)

lr_X_test_prediction = lr_model.predict(X_test)
lr_test_data_accuracy = accuracy_score(lr_X_test_prediction, Y_test)

# create a bar chart for accuracy on training and test data
labels = ['Training Data', 'Test Data']
accuracy = [lr_training_data_accuracy, lr_test_data_accuracy]
plt.bar(labels, accuracy)
plt.ylim([0, 1])
plt.ylabel('Accuracy')
plt.title('Logistic Regression Accuracy on Training and Test Data')
plt.show()

with open('lr_model.pkl', 'wb') as file:
    pickle.dump(lr_model, file)
    files.download('lr_model.pkl')

# create random forest model
rf_model = RandomForestClassifier(n_estimators=100)

# train the random forest model
rf_model.fit(X_train, Y_train)

# accuracy on training data
rf_X_train_prediction = rf_model.predict(X_train)
rf_training_data_accuracy = accuracy_score(rf_X_train_prediction, Y_train)
print('Random Forest Accuracy on Training data : ', rf_training_data_accuracy)

# accuracy on test data
rf_X_test_prediction = rf_model.predict(X_test)
rf_test_data_accuracy = accuracy_score(rf_X_test_prediction, Y_test)
print('Random Forest Accuracy on Test data : ', rf_test_data_accuracy)

# calculate accuracy on training and test data
rf_X_train_prediction = rf_model.predict(X_train)
rf_training_data_accuracy = accuracy_score(rf_X_train_prediction, Y_train)

rf_X_test_prediction = rf_model.predict(X_test)
rf_test_data_accuracy = accuracy_score(rf_X_test_prediction, Y_test)

# create a bar chart for accuracy on training and test data
labels = ['Training Data', 'Test Data']
accuracy = [rf_training_data_accuracy, rf_test_data_accuracy]
plt.bar(labels, accuracy)
plt.ylim([0, 1])
plt.ylabel('Accuracy')
plt.title('Random Forest Accuracy on Training and Test Data')
plt.show()

with open('rf_model.pkl', 'wb') as file:
    pickle.dump(rf_model, file)
    files.download('rf_model.pkl')

# create decision tree model
dt_model = DecisionTreeClassifier()

# train the decision tree model
dt_model.fit(X_train, Y_train)

# accuracy on training data
dt_X_train_prediction = dt_model.predict(X_train)
dt_training_data_accuracy = accuracy_score(dt_X_train_prediction, Y_train)
print('Decision Tree Accuracy on Training data : ', dt_training_data_accuracy)

# accuracy on test data
dt_X_test_prediction = dt_model.predict(X_test)
dt_test_data_accuracy = accuracy_score(dt_X_test_prediction, Y_test)
print('Decision Tree Accuracy on Test data : ', dt_test_data_accuracy)

# calculate accuracy on training and test data
dt_X_train_prediction = dt_model.predict(X_train)
dt_training_data_accuracy = accuracy_score(dt_X_train_prediction, Y_train)

dt_X_test_prediction = dt_model.predict(X_test)
dt_test_data_accuracy = accuracy_score(dt_X_test_prediction, Y_test)

# create a bar chart for accuracy on training and test data
labels = ['Training Data', 'Test Data']
accuracy = [dt_training_data_accuracy, dt_test_data_accuracy]
plt.bar(labels, accuracy)
plt.ylim([0, 1])
plt.ylabel('Accuracy')
plt.title('Decision Tree Accuracy on Training and Test Data')
plt.show()

with open('dt_model.pkl', 'wb') as file:
    pickle.dump(dt_model, file)
    files.download('dt_model.pkl')

#create naive bayes model
nb_model = GaussianNB()

#train the naive bayes model
nb_model.fit(X_train, Y_train)

#accuracy on training data
nb_X_train_prediction = nb_model.predict(X_train)
nb_training_data_accuracy = accuracy_score(nb_X_train_prediction, Y_train)
print('Naive Bayes Accuracy on Training data : ', nb_training_data_accuracy)

#accuracy on test data
nb_X_test_prediction = nb_model.predict(X_test)
nb_test_data_accuracy = accuracy_score(nb_X_test_prediction, Y_test)
print('Naive Bayes Accuracy on Test data : ', nb_test_data_accuracy)

# calculate accuracy on training and test data
nb_X_train_prediction = nb_model.predict(X_train)
nb_training_data_accuracy = accuracy_score(nb_X_train_prediction, Y_train)

nb_X_test_prediction = nb_model.predict(X_test)
nb_test_data_accuracy = accuracy_score(nb_X_test_prediction, Y_test)

# create a bar chart for accuracy on training and test data
labels = ['Training Data', 'Test Data']
accuracy = [nb_training_data_accuracy, nb_test_data_accuracy]
plt.bar(labels, accuracy)
plt.ylim([0, 1])
plt.ylabel('Accuracy')
plt.title('Naive Bayes Accuracy on Training and Test Data')
plt.show()

with open('nb_model.pkl', 'wb') as file:
    pickle.dump(nb_model, file)
    files.download('nb_model.pkl')

#create MLP model
mlp_model = MLPClassifier(hidden_layer_sizes=(50,50), max_iter=1000)

#train the MLP model
mlp_model.fit(X_train, Y_train)

#accuracy on training data
mlp_X_train_prediction = mlp_model.predict(X_train)
mlp_training_data_accuracy = accuracy_score(mlp_X_train_prediction, Y_train)
print('MLP Accuracy on Training data : ', mlp_training_data_accuracy)

#accuracy on test data
mlp_X_test_prediction = mlp_model.predict(X_test)
mlp_test_data_accuracy = accuracy_score(mlp_X_test_prediction, Y_test)
print('MLP Accuracy on Test data : ', mlp_test_data_accuracy)

# calculate accuracy on training and test data
mlp_X_train_prediction = mlp_model.predict(X_train)
mlp_training_data_accuracy = accuracy_score(mlp_X_train_prediction, Y_train)

mlp_X_test_prediction = mlp_model.predict(X_test)
mlp_test_data_accuracy = accuracy_score(mlp_X_test_prediction, Y_test)

# create a bar chart for accuracy on training and test data
labels = ['Training Data', 'Test Data']
accuracy = [mlp_training_data_accuracy, mlp_test_data_accuracy]
plt.bar(labels, accuracy)
plt.ylim([0, 1])
plt.ylabel('Accuracy')
plt.title('Multi Layer Perceptron Accuracy on Training and Test Data')
plt.show()

with open('mlp_model.pkl', 'wb') as file:
    pickle.dump(mlp_model, file)
    files.download('mlp_model.pkl')

#create SVC model
svc_model = SVC(kernel='linear')

#train the SVC model
svc_model.fit(X_train, Y_train)

#accuracy on training data
svc_X_train_prediction = svc_model.predict(X_train)
svc_training_data_accuracy = accuracy_score(svc_X_train_prediction, Y_train)
print('SVC Accuracy on Training data : ', svc_training_data_accuracy)

#accuracy on test data
svc_X_test_prediction = svc_model.predict(X_test)
svc_test_data_accuracy = accuracy_score(svc_X_test_prediction, Y_test)
print('SVC Accuracy on Test data : ', svc_test_data_accuracy)

# calculate accuracy on training and test data
svc_X_train_prediction = svc_model.predict(X_train)
svc_training_data_accuracy = accuracy_score(svc_X_train_prediction, Y_train)

svc_X_test_prediction = svc_model.predict(X_test)
svc_test_data_accuracy = accuracy_score(svc_X_test_prediction, Y_test)

# create a bar chart for accuracy on training and test data
labels = ['Training Data', 'Test Data']
accuracy = [svc_training_data_accuracy, svc_test_data_accuracy]
plt.bar(labels, accuracy)
plt.ylim([0, 1])
plt.ylabel('Accuracy')
plt.title('SVC Accuracy on Training and Test Data')
plt.show()

with open('svc_model.pkl', 'wb') as file:
    pickle.dump(svc_model, file)
    files.download('svc_model.pkl')

input_data = (62,0,0,140,268,0,0,160,0,3.6,0,2,2)

# change the input data to a numpy array
input_data_as_numpy_array= np.asarray(input_data)

# reshape the numpy array as we are predicting for only one instance
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

# make predictions using all the models
lr_prediction = lr_model.predict(input_data_reshaped)[0]
rf_prediction = rf_model.predict(input_data_reshaped)[0]
svc_prediction = svc_model.predict(input_data_reshaped)[0]
dt_prediction = dt_model.predict(input_data_reshaped)[0]
mlp_prediction = mlp_model.predict(input_data_reshaped)[0]
nb_prediction = nb_model.predict(input_data_reshaped)[0]

# combine the predictions using a voting system
votes = [lr_prediction, rf_prediction, svc_prediction, dt_prediction, mlp_prediction, nb_prediction]
total_votes = len(votes)
positive_votes = sum(votes)
negative_votes = total_votes - positive_votes

# make the final prediction based on the majority vote
if positive_votes > negative_votes:
    print('The Person has Heart Disease')
else:
    print('The Person does not have a Heart Disease')